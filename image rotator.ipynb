{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image rotator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This file constists of several steps to solve task of finding and rotating images in the right way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image rotator description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #confortable viewing of csv tables\n",
    "import numpy as np #work with arrays\n",
    "import cv2 #importing images\n",
    "import os #work with folders \n",
    "import matplotlib.pyplot as plt #show image\n",
    "from tqdm import tqdm #progress bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data, creating samples ---> https://docs.google.com/document/d/1OvSmoV72Yfnn36p74JobDxlmbEb5OoEshQLqgFBwKPw/edit?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.truth.csv') #importing file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(data))\n",
    "data.head() #verifying groundtruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#creating samples of different categories in different folders using os\n",
    "\n",
    "# import os\n",
    "\n",
    "# for index, row in data.iterrows():\n",
    "#     print(row['fn'], row['label'])\n",
    "# #     \n",
    "#     os.rename('/home/yurii/DeeperSystems/raw_data/'+row['fn'], \n",
    "#               '/home/yurii/DeeperSystems/data/'+row['label']+'/'+row['fn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#creating array where we will load our images\n",
    "training_data = []\n",
    "categories = ['rotated_left', 'upright', 'rotated_right', 'upside_down']\n",
    "\n",
    "\n",
    "def create_training_data(your_path = '/home/yurii/DeeperSystems/data/'): #check your path\n",
    "    '''Input: \n",
    "    your_path: str :: path where you get training images from\n",
    "    Returns: list :: list of image array and label to it\n",
    "    '''\n",
    "    for category in categories:  \n",
    "\n",
    "        path = os.path.join(your_path, category)  #your path\n",
    "        class_num = categories.index(category)  # get the classification  \n",
    "\n",
    "        for img in tqdm(os.listdir(path)):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img))# ,cv2.IMREAD_GRAYSCALE)  # convert to array\n",
    "                training_data.append([img_array, class_num])  # add this to our training_data\n",
    "            except Exception as e:  \n",
    "                pass\n",
    "            \n",
    "            \n",
    "create_training_data()\n",
    "\n",
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(training_data) #for training we have to shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "#Separating features and labels into X, y\n",
    "for features,label in training_data:\n",
    "    X.append(features)\n",
    "    \n",
    "    y.append(label)\n",
    "\n",
    "print(X[0].reshape(-1, 64, 64, 3))\n",
    "\n",
    "X = np.array(X).reshape(-1, 64, 64, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and loading our data using pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# pickle_out = open(\"X.pickle\",\"wb\")\n",
    "# pickle.dump(X, pickle_out)\n",
    "# pickle_out.close()\n",
    "\n",
    "# pickle_out = open(\"y.pickle\",\"wb\")\n",
    "# pickle.dump(y, pickle_out)\n",
    "# pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# pickle_in = open(\"X.pickle\",\"rb\")\n",
    "# X = pickle.load(pickle_in)\n",
    "\n",
    "# pickle_in = open(\"y.pickle\",\"rb\")\n",
    "# y = pickle.load(pickle_in)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Using test_size=0.33 to split data saved before\n",
    "X_train,  X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing keras and initializing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import load_model\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "# nb of  classes ('rotated_left', 'upright', 'rotated_right', 'upside_down')\n",
    "nb_classes = 4\n",
    "# number of epochs\n",
    "nb_epoch = 10\n",
    "# image size\n",
    "img_rows, img_cols = 64, 64\n",
    "# We didn`nt convert our image into grayscale so we have RGB\n",
    "img_channels = 3\n",
    "\n",
    "\n",
    "# Data normalization. better do here (after test_train_split) of MEMORY ERROR!!!!!!\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# labels to categories\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "# Model creation\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                        input_shape=(64, 64, 3), activation='relu'))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "#optimization parameters\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "# Training \n",
    "model.fit(X_train, Y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=nb_epoch,\n",
    "              validation_split=0.1,\n",
    "              shuffle=True,\n",
    "              verbose=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating our model on test data\n",
    "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"Accuracy on test data: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('image_rotator_net.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "del model  # deletes the existing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "model = load_model('image_rotator_net.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test data\n",
    "testing_data = []\n",
    "path = '/home/yurii/DeeperSystems/test'\n",
    "test_files = os.listdir(path)\n",
    "for img in tqdm(test_files): \n",
    "    try:\n",
    "        img_array = cv2.imread(os.path.join(path,img))\n",
    "        testing_data.append(img_array)  # add this to our training_data\n",
    "    except Exception as e:  \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#also normilizing. its better to use NumPy here to normilize data bewaring of memory error\n",
    "testing_data_n = np.divide(testing_data, 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(testing_data_n)\n",
    "predictions = [np.argmax(i) for i in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output = pd.DataFrame(list(zip(test_files, predictions)), \n",
    "               columns =['fn', 'label']) \n",
    "test_output['label'] = test_output['label'].map({\n",
    "        0:'rotated_left', \n",
    "        1:'upright', \n",
    "        2:'rotated_right', \n",
    "        3:'upside_down'\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output.to_csv('test.preds.csv') #saving ourout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotating images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using funtion from eval.py to create dictionary\n",
    "def load_csv(fn='test.preds.csv'):\n",
    "    res = {}\n",
    "    import csv\n",
    "    for row in csv.DictReader(open(fn)):\n",
    "        res[row['fn']] = row['label']\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_to_rotate = load_csv() #initializing dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_image(d, image):\n",
    "    '''rotate_image:\n",
    "    Input:\n",
    "    d: dict {'fn':'label'} :: consists of labeled images\n",
    "    image: str :: name of image which is in d\n",
    "    Returns: list :: rotated image array'''\n",
    "    \n",
    "    angle = 0\n",
    "    \n",
    "    if d[image] == 'rotated_right':\n",
    "        angle = 90\n",
    "\n",
    "    if d[image] == 'rotated_left':\n",
    "        angle = 270\n",
    "\n",
    "    if d[image] == 'upside_down':\n",
    "        angle = 180\n",
    "        \n",
    "    image = cv2.imread(os.path.join(path,image))\n",
    "    image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
    "    rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
    "    result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving to PNG!\n",
    "for i in im_to_rotate:\n",
    "    cv2.imwrite('/home/yurii/DeeperSystems/rotated_images/'+i[:-4]+'.png', rotate_image(im_to_rotate, i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating numpy output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using already known code, reading image\n",
    "numpy_output_data = []\n",
    "path = '/home/yurii/DeeperSystems/rotated_images/'\n",
    "test_files = os.listdir(path)\n",
    "for img in tqdm(test_files): \n",
    "    try:\n",
    "        img_array = cv2.imread(os.path.join(path,img))\n",
    "        numpy_output_data.append(img_array)  # add this to our training_data\n",
    "    except Exception as e:  \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_output = np.array(numpy_output_data).reshape(-1, 64, 64, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('numpy_output.out', numpy_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
